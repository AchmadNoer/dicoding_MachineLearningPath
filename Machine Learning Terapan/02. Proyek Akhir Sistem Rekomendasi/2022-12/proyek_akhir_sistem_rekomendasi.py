# -*- coding: utf-8 -*-
"""classic-video-game-recommender-system.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rYnsA9kMDUs1bPVsTA_sI1xXATRs0fh_

Analyze sales data from more than 16,500 games from Vgchartz and corresponding ratings from Metacritic.
* **Name** : Name of the game
* **Platform** : Console on which the game is running
* **Year_of_Release** : Year of the game released
* **Genre** : Game's category
* **Publisher** : Publisher
* **NA_Sales** : Game sales in North America (in millions of units)
* **EU_Sales** : Game sales in the European Union (in millions of units)
* **JP_Sales** : Game sales in Japan (in millions of units)
* **Other_Sales** : Game sales in the rest of the world
* **Global_Sales** : Total sales in the world (in millions of units)
* **Critic_Score** : Aggregate score compiled by Metacritic staff
* **Critic_Count** : The number of critics used in coming up with the Critic_score
* **User_Score** : Score by Metacritic's subscribers
* **User_Count** : Number of Metacritic's subscribers who gave the user_score
* **Developer** : Party responsible for creating the game
* **Rating** : The ESRB ratings

# Data Loading
"""

import pandas as pd
import matplotlib.pyplot as plt

import seaborn as sns
sns.set_theme(style="whitegrid")

import warnings
warnings.filterwarnings('ignore')

games = pd.read_csv("/kaggle/input/video-game-sales-with-ratings/Video_Games_Sales_as_at_22_Dec_2016.csv")
games

print("Ukuran DataFrame:", games.shape)

"""# Data Cleaning"""

games.info()

"""## 1.) Dropping Unused Columns"""

games.drop(['Publisher',
            'NA_Sales',
            'EU_Sales',
            'JP_Sales',
            'Other_Sales',
            'Critic_Count',
            'User_Score',
            'User_Count',
            'Developer',
            'Rating'], axis=1, inplace=True)
print("Ukuran DataFrame setelah drop kolom:", games.shape)

"""## 2.) Checking Missing Values"""

games.isna().sum()

games[games.isnull().any(axis=1)].head(3)

games.dropna(inplace=True)
print("Ukuran DataFrame setelah cleaning:", games.shape)

"""## 3.) Checking Duplicated Values"""

games.duplicated().sum()

games.drop_duplicates(inplace=True)
print("Ukuran DataFrame setelah cleaning:", games.shape)

"""## 4.) Grouping by Platform"""

print("Berbagai jenis platform:", games['Platform'].unique())

games['Platform_General']= games['Platform']

games.loc[games['Platform'] == 'Wii', 'Platform_General'] = 'Nintendo'
games.loc[games['Platform'] == 'DS', 'Platform_General'] = 'Nintendo'
games.loc[games['Platform'] == 'X360', 'Platform_General'] = 'Microsoft_Xbox'
games.loc[games['Platform'] == 'PS3', 'Platform_General'] = 'Sony_Playstation' 
games.loc[games['Platform'] == 'PS2', 'Platform_General'] = 'Sony_Playstation'
games.loc[games['Platform'] == '3DS', 'Platform_General'] = 'Nintendo'
games.loc[games['Platform'] == 'PS4', 'Platform_General'] = 'Sony_Playstation'
games.loc[games['Platform'] == 'PS', 'Platform_General'] = 'Sony_Playstation' 
games.loc[games['Platform'] == 'XB', 'Platform_General'] = 'Microsoft_Xbox'
games.loc[games['Platform'] == 'PC', 'Platform_General'] = 'PC'
games.loc[games['Platform'] == 'PSP', 'Platform_General'] = 'Sony_Playstation'
games.loc[games['Platform'] == 'WiiU', 'Platform_General'] = 'Nintendo'
games.loc[games['Platform'] == 'GC', 'Platform_General'] = 'Nintendo'
games.loc[games['Platform'] == 'GBA', 'Platform_General'] = 'Nintendo'
games.loc[games['Platform'] == 'XOne', 'Platform_General'] = 'Microsoft_Xbox'
games.loc[games['Platform'] == 'PSV', 'Platform_General'] = 'Sony_Playstation'
games.loc[games['Platform'] == 'DC', 'Platform_General'] = 'Sega'

games.head()

print("Berbagai jenis platform general:", games['Platform_General'].unique())

"""## 5.) Tidy Up Dataset"""

# mengubah tipe data sebuah kolom
games['Year_of_Release'] = games['Year_of_Release'].astype(int).astype(object)
games['Critic_Score'] = games['Critic_Score'].astype(int)

# mengganti nama value tertentu
duplicated_index = games[games.duplicated('Name', keep=False)].index.tolist()
games.loc[duplicated_index, "Platform"] = "Multi_Platform"
games.loc[duplicated_index, "Platform_General"] = "Multi_Platform"
games.loc[games['Genre'] == 'Role-Playing', 'Genre'] = 'Role_Playing'

# menggabungkan nama game yang sama
games['Global_Sales'] = games.groupby(['Name'])['Global_Sales'].transform('sum')
games = games.drop_duplicates(subset=['Name'])

# mengubah urutan kolom
games = games.reindex(columns=['Name','Platform','Platform_General','Year_of_Release','Genre','Global_Sales','Critic_Score'])
games = games.reset_index(drop=True)

games.sample(5)

"""# Exploring Data"""

games.info()

games.nunique()

games.describe()

"""## 1.) Univariate Analysis"""

count = games['Platform'].value_counts()
percent = 100*games['Platform'].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(2)})
print(df)
count.plot(kind='bar', title="Jumlah Game tiap Platform");

count = games['Platform_General'].value_counts()
percent = 100*games['Platform_General'].value_counts(normalize=True)
df = pd.DataFrame({'Jumlah':count, 'Persentase':percent.round(2)})
print(df)
count.plot(kind='bar', title="Jumlah Game tiap General Platform");

count = games['Year_of_Release'].value_counts().sort_index()
percent = 100*games['Year_of_Release'].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(2)})
print(df)
count.plot(kind='bar', title="Jumlah Game Rilis per Tahun");

count = games['Genre'].value_counts()
percent = 100*games['Genre'].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(2)})
print(df)
count.plot(kind='bar', title="Jumlah Game tiap Genre");

games.hist(bins=25, figsize=(12,5))
plt.show()

"""## 2.) Multivariate Analysis"""

df = games.groupby(['Genre','Platform_General']).Global_Sales.sum()
df.unstack().plot.bar(stacked=True, linewidth=0, figsize=(10,5))
plt.title('Penjualan Global Video Games tiap Platform pada Masing-masing Genre', size=16)
plt.ylabel('Penjualan Global (Juta)')
plt.xlabel('Genre')
plt.legend(loc=9, prop={'size': 10})
plt.autoscale()
plt.show()

df = games.groupby(['Year_of_Release','Platform_General']).Global_Sales.sum()
df.unstack().plot.bar(stacked=True, linewidth=0, figsize=(10,5))
plt.title('Penjualan Global tiap Platform dari Tahun ke tahun', size=16)
plt.ylabel('Penjualan Global (Juta)')
plt.xlabel('Tahun')
plt.legend(loc=2, prop={'size': 10})
plt.show()

df = games.groupby(['Critic_Score','Platform_General']).Global_Sales.sum()
df.unstack().plot.bar(stacked=True, linewidth=0, figsize=(20,5))
plt.title('Penjualan Global tiap Platform berdasarkan Skor Metacritic', size=16)
plt.ylabel('Penjualan Global (Juta)')
plt.xlabel('Skor Metacritic')
plt.legend(loc=2, prop={'size': 10})
plt.show()

"""# Development"""

dataset = games.copy()
dataset.sample(10)

"""## 1.) TF-IDF Vectorizer"""

from sklearn.feature_extraction.text import TfidfVectorizer
 
tf = TfidfVectorizer()
tf.fit(dataset['Genre']) 
tf.get_feature_names()

tfidf_matrix = tf.fit_transform(dataset['Genre']) 
tfidf_matrix.shape

tfidf_matrix.todense()

pd.DataFrame(
    tfidf_matrix.todense(), 
    columns=tf.get_feature_names(),
    index=dataset['Name']
).sample(12, axis=1).sample(10, axis=0)

"""## 2.) Cosine Similarity"""

from sklearn.metrics.pairwise import cosine_similarity
 
# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix) 
cosine_sim

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama game
cosine_sim_df = pd.DataFrame(cosine_sim, index=dataset['Name'], columns=dataset['Name'])
print('Shape:', cosine_sim_df.shape)
 
# Melihat similarity matrix pada setiap genre
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""## 3.) Getting Recommendation"""

def recommender_system(Name, k=500):
    similarity_data = cosine_sim_df
    items = dataset[['Name','Platform','Year_of_Release','Genre','Global_Sales','Critic_Score']]
    genre = dataset.loc[dataset["Name"] == Name].Genre.values

    index = similarity_data.loc[:,Name].to_numpy().argpartition(range(-1, -k, -1))
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    closest = closest.drop(Name, errors='ignore')
    
    goat = dataset.sort_values(by=['Critic_Score'],ascending=False).head(3)
    best_selling_genre = dataset.loc[dataset["Genre"] == genre[0]].sort_values(by=['Global_Sales'],ascending=False).head(5)
    recommendation = pd.DataFrame(closest).merge(items[['Name','Platform','Year_of_Release','Genre']]).head(k)
    
    return Name, goat, best_selling_genre, recommendation, genre

dataset[dataset['Name'].eq('Crash Team Racing')]

Name, goat, best_selling_genre, recommendation, genre = recommender_system("Crash Team Racing")

print("Top 3 Greatest Games of All Time:")
print("-----"*10)
for row1 in goat.itertuples():
    print('[Score: %d/100] %s (%s)'%(row1.Critic_Score,row1.Name,row1.Year_of_Release))

print("====="*10)  
print("Top 5 Best Selling %s Games of All Time:"%genre[0])
print("-----"*10)
for row2 in best_selling_genre.itertuples():
    print('%s (%s) - %s'%(row2.Name,row2.Year_of_Release,row2.Platform))

print("====="*10)
print("Since you play %s,"%Name)
print("here are the Top 10 Games you probably like:")
print("-----"*10)
for row3 in recommendation.head(10).itertuples():
    print('%s (%s) - %s'%(row3.Name,row3.Year_of_Release,row3.Platform))

"""# Evaluate"""

recommendation["Genre"].value_counts()

relevan = tidak_relevan = 0

for checking in recommendation.itertuples():
    if checking.Genre == genre[0]:
        relevan+=1
    else:
        tidak_relevan+=1
        
print("Out of a total of 500 recommendation lists,")
print("- Number of relevant recommendations:",relevan)
print("- Number of irrelevant recommendations:",tidak_relevan)
print("Precision Score =",(relevan/500))